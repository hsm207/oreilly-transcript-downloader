<!--
  Source: https://learning.oreilly.com/library/view/unlocking-the-secrets/9781835083833/B21161_01.xhtml#_idParaDest-24
-->
<div id="sbo-rt-content">
  <ul>
    <li>
      <strong class="bold">Fine-tuning</strong>: In fine-tuning, the LLM is trained on a small
      dataset of labeled examples for the task that it is <a id="_idIndexMarker020"></a>being asked
      to perform. This can be a more effective way to generate high-quality responses, but it
      requires a larger <a id="_idIndexMarker021"></a>dataset of
      <span class="No-Break">labeled examples.</span>
      <p class="list-inset">
        As an example, let’s say that the input is an article about new research on treating cancer,
        while the training data is articles about cancer research labeled
        <span class="No-Break">with </span
        ><span class="No-Break"><a id="_idIndexMarker022"></a></span
        ><span class="No-Break">summaries.</span>
      </p>
      <p class="list-inset">
        Here’s the<a id="_idIndexMarker023"></a> prompt <span class="No-Break">for this.</span>
      </p>
      <p class="list-inset"><span class="No-Break">Prompt:</span></p>
      <div data-testid="custom pre block" class="orm-ChapterReader-codeSnippetContainer">
        <pre class="source-code" tabindex="-1">
<span class="orm-highlight">
Summarize the key finding</span>s of the research described in the input article.</pre>
        <div class="orm-ChapterReader-snippetButtonContainer"></div>
      </div>
      <p class="list-inset">Here’s <span class="No-Break">the output.</span></p>
      <p class="list-inset"><span class="No-Break">Response:</span></p>
      <div data-testid="custom pre block" class="orm-ChapterReader-codeSnippetContainer">
        <pre class="source-code">
A short summarization highlighting the key points of the input article.</pre
        >
        <div class="orm-ChapterReader-snippetButtonContainer"></div>
      </div>
    </li>
  </ul>
</div>
